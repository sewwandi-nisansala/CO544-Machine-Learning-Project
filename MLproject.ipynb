{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.6 (default, Jan  8 2020, 19:59:22) \n",
      "[GCC 7.3.0]\n",
      "scipy: 1.4.1\n",
      "numpy: 1.18.1\n",
      "matplotlib: 3.1.3\n",
      "pandas: 1.0.1\n",
      "sklearn: 0.22.1\n"
     ]
    }
   ],
   "source": [
    "# Check the versions of libraries\n",
    "\n",
    "# Python version\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas \n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# making data frame from csv file  \n",
    "data = pd.read_csv(\"data.csv\")  \n",
    "\n",
    "# load test data file \n",
    "testdata = pd.read_csv(\"testdata_10%.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace('?', np.nan, inplace=True)\n",
    "testdata.replace('?', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print top 15 rows in test dataset\n",
      "    A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  A11  A12  A13  A14  A15\n",
      "0    1   9   1   1  11   6   0   0   1    8    1    0    1    4    0\n",
      "1    1   1   0   0   0   4   9   1   2    4    0    1    0    9    0\n",
      "2    1   1   0   0   1   4   0   0   2    0    0    0    0    7    0\n",
      "3    1   4   0   0   5   2   2   0   2    0    0    0    0    5    0\n",
      "4    0   6   0   0   2   3   3   1   1    0    0    1    1   10    0\n",
      "5    1   8   1   1   3   0   0   0   2    7    0    0    1   11    0\n",
      "6    0   2   0   0  10   1   6   0   2    1    0    0    0    0    0\n",
      "7    1  12   0   0   8   2   1   0   0    4    0    0    0    3    0\n",
      "8    1   7   0   0   7   1   0   0   2    1    0    0    0    8    0\n",
      "9    0  11   0   0   4   0   4   0   2    2    0    0    0    9    0\n",
      "10   1  10   0   0   4   5  10   0   1    9    1    0    1    6    0\n",
      "11   0   0   0   0  11   0   8   1   2    3    1    2    0    2    0\n",
      "12   0   5   0   0   6   4   7   1   1    5    1    3    0    0    0\n",
      "13   1   3   1   1   9   6   5   1   2    6    1    1    1    1    0\n"
     ]
    }
   ],
   "source": [
    "print('print top 15 rows in test dataset')\n",
    "# head\n",
    "print(testdata.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with high frequency values\n",
    "data = data.fillna({\"A1\": \"b\"})\n",
    "data = data.fillna({\"A2\": \"24.5\"})\n",
    "data = data.fillna({\"A3\": \"u\"})\n",
    "data = data.fillna({\"A4\": \"g\"})\n",
    "data = data.fillna({\"A6\": \"c\"})\n",
    "data = data.fillna({\"A9\": \"v\"})\n",
    "data = data.fillna({\"A15\": \"g\"})\n",
    "data = data.fillna({\"A8\": \"False\"})\n",
    "data = data.fillna({\"A11\": \"True\"})\n",
    "data = data.fillna({\"A13\": \"False\"})\n",
    "data = data.fillna({\"A14\": \"0\"})\n",
    "\n",
    "#replace missing values with high frequency values in test dataset\n",
    "testdata = testdata.fillna({\"A1\": \"b\"})\n",
    "testdata = testdata.fillna({\"A2\": \"24.5\"})\n",
    "testdata = testdata.fillna({\"A3\": \"u\"})\n",
    "testdata = testdata.fillna({\"A4\": \"g\"})\n",
    "testdata = testdata.fillna({\"A6\": \"c\"})\n",
    "testdata = testdata.fillna({\"A9\": \"v\"})\n",
    "testdata = testdata.fillna({\"A15\": \"g\"})\n",
    "testdata = testdata.fillna({\"A8\": \"False\"})\n",
    "testdata = testdata.fillna({\"A11\": \"True\"})\n",
    "testdata = testdata.fillna({\"A13\": \"False\"})\n",
    "testdata = testdata.fillna({\"A14\": \"0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print top 15 rows in test dataset after filling missing values \n",
      "    A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  A11  A12  A13  A14  A15\n",
      "0    1   9   1   1  11   6   0   0   1    8    1    0    1    4    0\n",
      "1    1   1   0   0   0   4   9   1   2    4    0    1    0    9    0\n",
      "2    1   1   0   0   1   4   0   0   2    0    0    0    0    7    0\n",
      "3    1   4   0   0   5   2   2   0   2    0    0    0    0    5    0\n",
      "4    0   6   0   0   2   3   3   1   1    0    0    1    1   10    0\n",
      "5    1   8   1   1   3   0   0   0   2    7    0    0    1   11    0\n",
      "6    0   2   0   0  10   1   6   0   2    1    0    0    0    0    0\n",
      "7    1  12   0   0   8   2   1   0   0    4    0    0    0    3    0\n",
      "8    1   7   0   0   7   1   0   0   2    1    0    0    0    8    0\n",
      "9    0  11   0   0   4   0   4   0   2    2    0    0    0    9    0\n",
      "10   1  10   0   0   4   5  10   0   1    9    1    0    1    6    0\n",
      "11   0   0   0   0  11   0   8   1   2    3    1    2    0    2    0\n",
      "12   0   5   0   0   6   4   7   1   1    5    1    3    0    0    0\n",
      "13   1   3   1   1   9   6   5   1   2    6    1    1    1    1    0\n"
     ]
    }
   ],
   "source": [
    "print('print top 15 rows in test dataset after filling missing values ')\n",
    "# head\n",
    "print(testdata.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorial data\n",
    "labelencoder = LabelEncoder()\n",
    "data['A1'] = labelencoder.fit_transform(data['A1'])\n",
    "data['A2'] = labelencoder.fit_transform(data['A2'])\n",
    "data['A3'] = labelencoder.fit_transform(data['A3'])\n",
    "data['A4'] = labelencoder.fit_transform(data['A4'])\n",
    "data['A5'] = labelencoder.fit_transform(data['A5'])\n",
    "data['A6'] = labelencoder.fit_transform(data['A6'])\n",
    "data['A7'] = labelencoder.fit_transform(data['A7'])\n",
    "data['A8'] = labelencoder.fit_transform(data['A8'])\n",
    "data['A9'] = labelencoder.fit_transform(data['A9'])\n",
    "data['A10'] = labelencoder.fit_transform(data['A10'])\n",
    "data['A11'] = labelencoder.fit_transform(data['A11'])\n",
    "data['A12'] = labelencoder.fit_transform(data['A12'])\n",
    "data['A13'] = labelencoder.fit_transform(data['A13'])\n",
    "data['A14'] = labelencoder.fit_transform(data['A14'])\n",
    "data['A15'] = labelencoder.fit_transform(data['A15'])\n",
    "data['A16'] = labelencoder.fit_transform(data['A16'])\n",
    "\n",
    "#Encoding categorial testdata\n",
    "testdata['A1'] = labelencoder.fit_transform(testdata['A1'])\n",
    "testdata['A2'] = labelencoder.fit_transform(testdata['A2'])\n",
    "testdata['A3'] = labelencoder.fit_transform(testdata['A3'])\n",
    "testdata['A4'] = labelencoder.fit_transform(testdata['A4'])\n",
    "testdata['A5'] = labelencoder.fit_transform(testdata['A5'])\n",
    "testdata['A6'] = labelencoder.fit_transform(testdata['A6'])\n",
    "testdata['A7'] = labelencoder.fit_transform(testdata['A7'])\n",
    "testdata['A8'] = labelencoder.fit_transform(testdata['A8'])\n",
    "testdata['A9'] = labelencoder.fit_transform(testdata['A9'])\n",
    "testdata['A10'] = labelencoder.fit_transform(testdata['A10'])\n",
    "testdata['A11'] = labelencoder.fit_transform(testdata['A11'])\n",
    "testdata['A12'] = labelencoder.fit_transform(testdata['A12'])\n",
    "testdata['A13'] = labelencoder.fit_transform(testdata['A13'])\n",
    "testdata['A14'] = labelencoder.fit_transform(testdata['A14'])\n",
    "testdata['A15'] = labelencoder.fit_transform(testdata['A15'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print top 15 rows of test dataset after encoding \n",
      "    A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  A11  A12  A13  A14  A15\n",
      "0    1   9   1   1  11   6   0   0   1    8    1    0    1    4    0\n",
      "1    1   1   0   0   0   4   9   1   2    4    0    1    0    9    0\n",
      "2    1   1   0   0   1   4   0   0   2    0    0    0    0    7    0\n",
      "3    1   4   0   0   5   2   2   0   2    0    0    0    0    5    0\n",
      "4    0   6   0   0   2   3   3   1   1    0    0    1    1   10    0\n",
      "5    1   8   1   1   3   0   0   0   2    7    0    0    1   11    0\n",
      "6    0   2   0   0  10   1   6   0   2    1    0    0    0    0    0\n",
      "7    1  12   0   0   8   2   1   0   0    4    0    0    0    3    0\n",
      "8    1   7   0   0   7   1   0   0   2    1    0    0    0    8    0\n",
      "9    0  11   0   0   4   0   4   0   2    2    0    0    0    9    0\n",
      "10   1  10   0   0   4   5  10   0   1    9    1    0    1    6    0\n",
      "11   0   0   0   0  11   0   8   1   2    3    1    2    0    2    0\n",
      "12   0   5   0   0   6   4   7   1   1    5    1    3    0    0    0\n",
      "13   1   3   1   1   9   6   5   1   2    6    1    1    1    1    0\n"
     ]
    }
   ],
   "source": [
    "print('print top 15 rows of test dataset after encoding ')\n",
    "# head\n",
    "print(testdata.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split-out validation dataset\n",
    "array = data.values\n",
    "X = array[:,0:15]\n",
    "y = array[:,15]\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_validation = sc_X.fit_transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm Classifier\n",
      "Accuracy: 0.8918918918918919\n",
      "Precision: 0.8867924528301887\n",
      "Recall: 0.8867924528301887\n",
      "[[52  6]\n",
      " [ 6 47]]\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        58\n",
      "           1       0.89      0.89      0.89        53\n",
      "\n",
      "    accuracy                           0.89       111\n",
      "   macro avg       0.89      0.89      0.89       111\n",
      "weighted avg       0.89      0.89      0.89       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('svm Classifier')\n",
    "# Make predictions on validation dataset\n",
    "model = SVC(gamma='auto')\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_validation)\n",
    "# Evaluate predictions\n",
    "print(\"Accuracy:\",accuracy_score(y_validation, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_validation, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred))\n",
    "print(confusion_matrix(y_validation, predictions))\n",
    "print('classification_report: ')\n",
    "print(classification_report(y_validation, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighbors Classifier\n",
      "Accuracy: 0.8468468468468469\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 0.7358490566037735\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        58\n",
      "           1       0.93      0.74      0.82        53\n",
      "\n",
      "    accuracy                           0.85       111\n",
      "   macro avg       0.86      0.84      0.84       111\n",
      "weighted avg       0.86      0.85      0.84       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('KNeighbors Classifier')\n",
    "#Create KNN Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_validation)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_validation, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred))\n",
    "print('classification_report: ')\n",
    "print(classification_report(y_validation, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Classifier\n",
      "Accuracy: 0.8648648648648649\n",
      "Precision: 0.9130434782608695\n",
      "Recall: 0.7924528301886793\n",
      "classification_report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88        58\n",
      "           1       0.91      0.79      0.85        53\n",
      "\n",
      "    accuracy                           0.86       111\n",
      "   macro avg       0.87      0.86      0.86       111\n",
      "weighted avg       0.87      0.86      0.86       111\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gaussian Classifier')\n",
    "#Create a Gaussian Classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "#Train the model using the training sets\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_validation)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_validation, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred))\n",
    "print('classification_report: ')\n",
    "print(classification_report(y_validation, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Classifier\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0024d0408bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RandomForest Classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Create a Gaussian Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Train the model using the training sets y_pred=clf.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "print('RandomForest Classifier')\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_validation)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_validation, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_validation, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_validation, y_pred))\n",
    "print('classification_report: ')\n",
    "print(classification_report(y_validation, y_pred))\n",
    "\n",
    "testpred=clf.predict(testdata)\n",
    "print(testpred)\n",
    "print(testpred.replace('1', 'success'))\n",
    "print(\"testpred (1-> success & 0-> Failure):\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
